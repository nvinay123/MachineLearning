{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_758</th>\n",
       "      <th>embed_759</th>\n",
       "      <th>embed_760</th>\n",
       "      <th>embed_761</th>\n",
       "      <th>embed_762</th>\n",
       "      <th>embed_763</th>\n",
       "      <th>embed_764</th>\n",
       "      <th>embed_765</th>\n",
       "      <th>embed_766</th>\n",
       "      <th>embed_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.029216</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>-0.045125</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045697</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>-0.056139</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>-0.016137</td>\n",
       "      <td>-0.009309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007535</td>\n",
       "      <td>-0.039844</td>\n",
       "      <td>0.030167</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.028289</td>\n",
       "      <td>-0.068723</td>\n",
       "      <td>0.039153</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>-0.027138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056834</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>-0.034220</td>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.045456</td>\n",
       "      <td>0.027402</td>\n",
       "      <td>0.017837</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>-0.010062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022408</td>\n",
       "      <td>-0.030840</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.046965</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>-0.065093</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>-0.029205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016249</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>-0.034288</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>0.040412</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>-0.034122</td>\n",
       "      <td>-0.017289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019677</td>\n",
       "      <td>-0.034055</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.070387</td>\n",
       "      <td>-0.011170</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>-0.050945</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>0.034781</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038879</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>-0.053278</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>-0.011774</td>\n",
       "      <td>-0.011125</td>\n",
       "      <td>-0.017540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017678</td>\n",
       "      <td>-0.030323</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.065267</td>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>-0.050590</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>-0.015004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042079</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.010147</td>\n",
       "      <td>-0.035857</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.009884</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>-0.029238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.019743</td>\n",
       "      <td>-0.071799</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.049042</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>-0.016275</td>\n",
       "      <td>-0.037731</td>\n",
       "      <td>0.029718</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.030913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040456</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.026138</td>\n",
       "      <td>-0.056447</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>-0.046791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-0.040816</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026985</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>-0.037808</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>-0.010890</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>-0.015145</td>\n",
       "      <td>-0.045444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.018066</td>\n",
       "      <td>-0.032152</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>-0.056508</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>-0.026038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041547</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>-0.016882</td>\n",
       "      <td>-0.059904</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.029574</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.017324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-0.003492</td>\n",
       "      <td>-0.022739</td>\n",
       "      <td>0.021777</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>-0.005621</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>-0.079196</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>-0.015787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057920</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>-0.007196</td>\n",
       "      <td>-0.041652</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.047604</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.016415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.013689</td>\n",
       "      <td>-0.037855</td>\n",
       "      <td>0.039763</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>-0.050556</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039500</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.048696</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.036328</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>-0.021304</td>\n",
       "      <td>-0.032017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    0.009625 -0.029216  0.027109  0.023631 -0.004972  0.031757 -0.045125   \n",
       "1   -0.007535 -0.039844  0.030167  0.031224  0.004742  0.028289 -0.068723   \n",
       "2    0.022408 -0.030840  0.032328  0.046965  0.007798  0.025860 -0.065093   \n",
       "3    0.019677 -0.034055  0.012662  0.070387 -0.011170  0.017842 -0.050945   \n",
       "4    0.017678 -0.030323  0.012829  0.065267 -0.025161  0.011964 -0.050590   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.019743 -0.071799  0.022546  0.049042 -0.005767 -0.016275 -0.037731   \n",
       "896  0.000186 -0.027604  0.010623  0.038237 -0.026675  0.020215 -0.040816   \n",
       "897  0.018066 -0.032152  0.039794  0.047608  0.003898  0.024092 -0.056508   \n",
       "898 -0.003492 -0.022739  0.021777  0.044054 -0.005621  0.013863 -0.079196   \n",
       "899  0.013689 -0.037855  0.039763  0.035750  0.004115  0.005637 -0.050556   \n",
       "\n",
       "      embed_7   embed_8   embed_9  ...  embed_758  embed_759  embed_760  \\\n",
       "0    0.044483  0.019400 -0.017189  ...  -0.045697  -0.001972  -0.008154   \n",
       "1    0.039153  0.019596 -0.027138  ...  -0.056834   0.008613  -0.006578   \n",
       "2    0.035118  0.035359 -0.029205  ...  -0.016249   0.020413  -0.034288   \n",
       "3    0.044878  0.034781 -0.025772  ...  -0.038879   0.002963  -0.018754   \n",
       "4    0.042820  0.029161 -0.015004  ...  -0.042079   0.010192  -0.010147   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "895  0.029718  0.009203 -0.030913  ...  -0.040456  -0.001192  -0.026138   \n",
       "896  0.032210  0.041016 -0.014836  ...  -0.026985   0.015479  -0.003967   \n",
       "897  0.020527  0.031972 -0.026038  ...  -0.041547   0.011308  -0.016882   \n",
       "898  0.039150  0.004557 -0.015787  ...  -0.057920   0.004005  -0.007196   \n",
       "899  0.024668  0.025077 -0.029114  ...  -0.039500  -0.000129  -0.003880   \n",
       "\n",
       "     embed_761  embed_762  embed_763  embed_764  embed_765  embed_766  \\\n",
       "0    -0.056139   0.009890   0.042366   0.040134   0.009304  -0.016137   \n",
       "1    -0.034220   0.027574   0.045456   0.027402   0.017837  -0.035009   \n",
       "2    -0.050649   0.028408   0.040412   0.030261   0.003535  -0.034122   \n",
       "3    -0.053278   0.033005   0.031635   0.022544  -0.011774  -0.011125   \n",
       "4    -0.035857   0.021784   0.034621   0.017342  -0.009884  -0.010316   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "895  -0.056447   0.015818   0.045241   0.012620  -0.004837  -0.014540   \n",
       "896  -0.037808   0.021234   0.031012  -0.010890   0.003081  -0.015145   \n",
       "897  -0.059904   0.009558   0.039976   0.029574   0.013737  -0.003724   \n",
       "898  -0.041652   0.020945   0.047604   0.019767   0.005806  -0.019280   \n",
       "899  -0.048696   0.015711   0.039773   0.036328   0.010483  -0.021304   \n",
       "\n",
       "     embed_767  \n",
       "0    -0.009309  \n",
       "1    -0.010062  \n",
       "2    -0.017289  \n",
       "3    -0.017540  \n",
       "4    -0.029238  \n",
       "..         ...  \n",
       "895  -0.046791  \n",
       "896  -0.045444  \n",
       "897  -0.017324  \n",
       "898  -0.016415  \n",
       "899  -0.032017  \n",
       "\n",
       "[900 rows x 768 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_project = pd.read_csv(r'C:\\Users\\Lenovo\\OneDrive\\Desktop\\Jupyter\\Machine Learning\\embeddingsdata.csv')\n",
    "dataframe_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m clf \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train the classifier\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Get the support vectors\u001b[39;00m\n\u001b[0;32m     17\u001b[0m support_vectors \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39msupport_vectors_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1165\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1165\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 3]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "# Assuming X_train is your feature matrix and y_train is the corresponding labels\n",
    "# Replace X_train and y_train with your actual data\n",
    "X_train = np.array([dataframe_project.embed_5,dataframe_project.embed_6])\n",
    "\n",
    "y_train = np.array([0, 1, 0])  # Replace with your actual labels\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the support vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "\n",
    "# Print or analyze the support vectors\n",
    "print(\"Support Vectors:\")\n",
    "print(support_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the support vector machine model is:  0.9467162329615861\n"
     ]
    }
   ],
   "source": [
    "# Question A2:\n",
    "# Test the accuracy of the SVM model\n",
    "\n",
    "print(\"The accuracy of the support vector machine model is: \", machine.score(dataframe_input_test, dataframe_output_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the corresponding vector the output is:  [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question A3:\n",
    "# Predict a given input to a class value\n",
    "print(\"For the corresponding vector the output is: \", machine.predict([input_dataframe.iloc[45, :]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model using the polynomial function gives the accuracy of:  0.9442379182156134\n"
     ]
    }
   ],
   "source": [
    "# Question A4:\n",
    "# Train the data using different kernel functions\n",
    "machine_poly = svm.SVC(kernel='poly')\n",
    "\n",
    "machine_poly.fit(dataframe_input_train, dataframe_output_train)\n",
    "print(\"The model using the polynomial function gives the accuracy of: \", machine_poly.score(dataframe_input_test, dataframe_output_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model using the radial basis function gives the accuracy of:  0.9467162329615861\n"
     ]
    }
   ],
   "source": [
    "machine_rbf = svm.SVC(kernel='rbf')\n",
    "\n",
    "machine_rbf.fit(dataframe_input_train, dataframe_output_train)\n",
    "print(\"The model using the radial basis function gives the accuracy of: \", machine_rbf.score(dataframe_input_test, dataframe_output_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model using the sigmoid function gives the accuracy of:  0.8091697645600991\n"
     ]
    }
   ],
   "source": [
    "machine_sigmoid = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "machine_sigmoid.fit(dataframe_input_train, dataframe_output_train)\n",
    "print(\"The model using the sigmoid function gives the accuracy of: \", machine_sigmoid.score(dataframe_input_test, dataframe_output_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model using the linear function gives the accuracy of:  0.9454770755885997\n"
     ]
    }
   ],
   "source": [
    "machine_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "machine_linear.fit(dataframe_input_train, dataframe_output_train)\n",
    "print(\"The model using the linear function gives the accuracy of: \", machine_linear.score(dataframe_input_test, dataframe_output_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
